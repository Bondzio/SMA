{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository numbers: 2960\n",
      "https://github.com/natcap/natgeo-dams' : \n",
      "['pypng', 'requests', 'alabaster', 'codecov', 'detox', 'docutils', 'flake8', 'httpbin', 'more-itertools', 'pysocks', 'pytest', 'pytest-cov', 'pytest-httpbin', 'pytest-mock', 'pytest-xdist', 'readme-renderer', 'sphinx', 'tox', 'apipkg', 'appdirs', 'atomicwrites', 'attrs', 'babel', 'bleach', 'blinker', 'brotlipy', 'certifi', 'cffi', 'chardet', 'click', 'configparser', 'contextlib2', 'coverage', 'decorator', 'distlib', 'dnspython', 'entrypoints', 'enum34', 'eventlet', 'execnet', 'filelock', 'flask', 'funcsigs', 'functools32', 'greenlet', 'idna', 'imagesize', 'importlib-metadata', 'importlib-resources', 'itsdangerous', 'jinja2', 'markupsafe', 'mccabe', 'mock', 'monotonic', 'pathlib2', 'pluggy', 'py', 'pycodestyle', 'pycparser', 'pyflakes', 'pygments', 'pytest-forked', 'pytz', 'raven', 'scandir', 'singledispatch', 'six', 'snowballstemmer', 'toml', 'typing', 'urllib3', 'virtualenv', 'webencodings', 'werkzeug', 'zipp']\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "input_file ='../data/results_3k_2hop.json'\n",
    "\n",
    "# with open(input_file) as f:\n",
    "#     repo_data = json.load(f,strict=False)\n",
    "#  JSONDecodeError: Extra data: line 2 column 1 (char 969)\n",
    "    \n",
    "file = open(input_file, 'r', encoding='utf-8')\n",
    "repo_data = {}\n",
    "for line in file.readlines():\n",
    "    dic = json.loads(line)\n",
    "    repo_data = {**repo_data,**dic}\n",
    "    \n",
    "print(f'Repository numbers: {len(repo_data)}')\n",
    "print(f'''https://github.com/natcap/natgeo-dams' : \n",
    "{repo_data['https://github.com/natcap/natgeo-dams']}\n",
    "{len(repo_data['https://github.com/natcap/natgeo-dams'])}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_file = '../data/keywords_description.json'\n",
    "\n",
    "f = open(kw_file,encoding='utf-8')\n",
    "kw_dict = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12062"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the key words for each repository\n",
    "keywords_dict = {}\n",
    "for i in kw_dict['results']['bindings']:\n",
    "    # 'https://github.com/' +\n",
    "    repo_url_list =  i['soft']['value'].split('/')\n",
    "    position = repo_url_list.index('Software')\n",
    "    software_name = ''\n",
    "    for j in range(position+1,len(repo_url_list)):\n",
    "        software_name += repo_url_list[j] + '/'\n",
    "    repo_url = 'https://github.com/' + software_name[:-1]\n",
    "    \n",
    "    key_words = i['description_keywords']['value']\n",
    "    keywords_dict[repo_url] = key_words\n",
    "\n",
    "len(keywords_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2783"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for repo_url in repo_data.keys():\n",
    "    try:\n",
    "        repo_data[repo_url].extend(keywords_dict[repo_url].split(','))\n",
    "    except:\n",
    "        pass\n",
    "len(repo_kw_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository numbers: 2960\n",
      "https://github.com/natcap/natgeo-dams' : \n",
      "['pypng', 'requests', 'alabaster', 'codecov', 'detox', 'docutils', 'flake8', 'httpbin', 'more-itertools', 'pysocks', 'pytest', 'pytest-cov', 'pytest-httpbin', 'pytest-mock', 'pytest-xdist', 'readme-renderer', 'sphinx', 'tox', 'apipkg', 'appdirs', 'atomicwrites', 'attrs', 'babel', 'bleach', 'blinker', 'brotlipy', 'certifi', 'cffi', 'chardet', 'click', 'configparser', 'contextlib2', 'coverage', 'decorator', 'distlib', 'dnspython', 'entrypoints', 'enum34', 'eventlet', 'execnet', 'filelock', 'flask', 'funcsigs', 'functools32', 'greenlet', 'idna', 'imagesize', 'importlib-metadata', 'importlib-resources', 'itsdangerous', 'jinja2', 'markupsafe', 'mccabe', 'mock', 'monotonic', 'pathlib2', 'pluggy', 'py', 'pycodestyle', 'pycparser', 'pyflakes', 'pygments', 'pytest-forked', 'pytz', 'raven', 'scandir', 'singledispatch', 'six', 'snowballstemmer', 'toml', 'typing', 'urllib3', 'virtualenv', 'webencodings', 'werkzeug', 'zipp', 'repo', ' code', ' grant', ' dams', ' natgeo']\n",
      "81\n"
     ]
    }
   ],
   "source": [
    "print(f'Repository numbers: {len(repo_data)}')\n",
    "print(f'''https://github.com/natcap/natgeo-dams' : \n",
    "{repo_data['https://github.com/natcap/natgeo-dams']}\n",
    "{len(repo_data['https://github.com/natcap/natgeo-dams'])}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreProcessing\n",
    "1. Get distinct dependency file dictionary -> dep_dict\n",
    "2. Sort dependency file  by frequency.     -> sort_dep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct dependency file: 43412\n",
      "\n",
      "Frequent dependency files:  [('eslint', 18303), ('chalk', 16688), ('ansi-regex', 15700), ('ansi-styles', 15633), ('argparse', 15324), ('debug', 15126), ('ajv', 14907), ('glob', 14768), ('acorn', 14193), ('@babel/code-frame', 13530), ('@babel/highlight', 13387), ('anymatch', 13147), ('@types/node', 12956), ('ansi-escapes', 12614), ('rimraf', 12580), ('lodash', 12272), ('commander', 12212), ('arr-flatten', 12087), ('arr-diff', 12025), ('@babel/types', 11979)]\n"
     ]
    }
   ],
   "source": [
    "rep_list,dep_list = [],[]\n",
    "for k,v in repo_data.items():\n",
    "    rep_list.append(k)\n",
    "    dep_list.append(v)\n",
    "    \n",
    "dep_dict = {}\n",
    "for deps in repo_data.values():\n",
    "    for i in deps:\n",
    "        dep_dict[i] = dep_dict.get(i,0)+1\n",
    "\n",
    "print(f'Distinct dependency file: {len(dep_dict)}',end='\\n\\n')\n",
    "        \n",
    "sort_dep = sorted(dep_dict.items(),key=lambda x: x[-1], reverse=True)\n",
    "print(f'Frequent dependency files:  {sort_dep[:20]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding\n",
    "1. Build dependency file index table ->  id2word  format: {0: 'ipython',1: 'jupyter-sphinx',....}\n",
    "2. Build Corpus   -> corpus    format: [[repo1 info],   [repo2 info]   ]  repo1_info:  [ (dep1_id:fre), xxx  ]\n",
    "3. Build a LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repos info: [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 1), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 1), (71, 1), (72, 1), (73, 1), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(' code', 1),\n",
       "  (' dams', 1),\n",
       "  (' grant', 1),\n",
       "  (' natgeo', 1),\n",
       "  ('alabaster', 1),\n",
       "  ('apipkg', 1),\n",
       "  ('appdirs', 1),\n",
       "  ('atomicwrites', 1),\n",
       "  ('attrs', 1),\n",
       "  ('babel', 1),\n",
       "  ('bleach', 1),\n",
       "  ('blinker', 1),\n",
       "  ('brotlipy', 1),\n",
       "  ('certifi', 1),\n",
       "  ('cffi', 1),\n",
       "  ('chardet', 1),\n",
       "  ('click', 1),\n",
       "  ('codecov', 1),\n",
       "  ('configparser', 1),\n",
       "  ('contextlib2', 1),\n",
       "  ('coverage', 1),\n",
       "  ('decorator', 1),\n",
       "  ('detox', 1),\n",
       "  ('distlib', 1),\n",
       "  ('dnspython', 1),\n",
       "  ('docutils', 1),\n",
       "  ('entrypoints', 1),\n",
       "  ('enum34', 1),\n",
       "  ('eventlet', 1),\n",
       "  ('execnet', 1),\n",
       "  ('filelock', 1),\n",
       "  ('flake8', 1),\n",
       "  ('flask', 1),\n",
       "  ('funcsigs', 1),\n",
       "  ('functools32', 1),\n",
       "  ('greenlet', 1),\n",
       "  ('httpbin', 1),\n",
       "  ('idna', 1),\n",
       "  ('imagesize', 1),\n",
       "  ('importlib-metadata', 1),\n",
       "  ('importlib-resources', 1),\n",
       "  ('itsdangerous', 1),\n",
       "  ('jinja2', 1),\n",
       "  ('markupsafe', 1),\n",
       "  ('mccabe', 1),\n",
       "  ('mock', 1),\n",
       "  ('monotonic', 1),\n",
       "  ('more-itertools', 1),\n",
       "  ('pathlib2', 1),\n",
       "  ('pluggy', 1),\n",
       "  ('py', 1),\n",
       "  ('pycodestyle', 1),\n",
       "  ('pycparser', 1),\n",
       "  ('pyflakes', 1),\n",
       "  ('pygments', 1),\n",
       "  ('pypng', 1),\n",
       "  ('pysocks', 1),\n",
       "  ('pytest', 1),\n",
       "  ('pytest-cov', 1),\n",
       "  ('pytest-forked', 1),\n",
       "  ('pytest-httpbin', 1),\n",
       "  ('pytest-mock', 1),\n",
       "  ('pytest-xdist', 1),\n",
       "  ('pytz', 1),\n",
       "  ('raven', 1),\n",
       "  ('readme-renderer', 1),\n",
       "  ('repo', 1),\n",
       "  ('requests', 1),\n",
       "  ('scandir', 1),\n",
       "  ('singledispatch', 1),\n",
       "  ('six', 1),\n",
       "  ('snowballstemmer', 1),\n",
       "  ('sphinx', 1),\n",
       "  ('toml', 1),\n",
       "  ('tox', 1),\n",
       "  ('typing', 1),\n",
       "  ('urllib3', 1),\n",
       "  ('virtualenv', 1),\n",
       "  ('webencodings', 1),\n",
       "  ('werkzeug', 1),\n",
       "  ('zipp', 1)]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# based on dep file names , build dep name dictionary\n",
    "id2word  = corpora.Dictionary(list(repo_data.values()))   # {0: 'emd-signal',1: 'numpy', 2: 'SQLAlchemy', 3: 'aiofiles' ....}\n",
    "\n",
    "# based on dep name dict and dep names, build corpus\n",
    "corpus = [id2word.doc2bow(text) for text in list(repo_data.values())] # [[(0, 1), (1, 1)],.....]\n",
    "\n",
    "\n",
    "print(f'repos info: {corpus[0]}')    #(0, 1)\n",
    "\n",
    "[[(id2word[id_], freq) for id_, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster number: 2 Coherence Score 0.6680153909417157 Perplexity: -7.515330049778937\n",
      "=======================================================\n",
      "cluster number: 3 Coherence Score 0.7565240370653714 Perplexity: -7.387527486745803\n",
      "=======================================================\n",
      "cluster number: 4 Coherence Score 0.8030349279018694 Perplexity: -7.35421383157777\n",
      "=======================================================\n",
      "cluster number: 5 Coherence Score 0.7378692645987809 Perplexity: -7.332937306083405\n",
      "=======================================================\n",
      "cluster number: 6 Coherence Score 0.7213421546539606 Perplexity: -7.330128431728066\n",
      "=======================================================\n",
      "cluster number: 7 Coherence Score 0.7216403494444983 Perplexity: -7.347507674964047\n",
      "=======================================================\n",
      "cluster number: 8 Coherence Score 0.692931712808801 Perplexity: -7.365108755501163\n",
      "=======================================================\n",
      "cluster number: 9 Coherence Score 0.6958168950563779 Perplexity: -7.411038985036263\n",
      "=======================================================\n",
      "cluster number: 10 Coherence Score 0.688689927890405 Perplexity: -7.478166970016604\n",
      "=======================================================\n",
      "cluster number: 11 Coherence Score 0.7346349897905575 Perplexity: -7.532862139589088\n",
      "=======================================================\n",
      "cluster number: 12 Coherence Score 0.6870571283367437 Perplexity: -7.618001847602874\n",
      "=======================================================\n",
      "cluster number: 13 Coherence Score 0.7742587187133879 Perplexity: -7.707467603550034\n",
      "=======================================================\n",
      "cluster number: 14 Coherence Score 0.6882567397826493 Perplexity: -7.759577926367446\n",
      "=======================================================\n",
      "cluster number: 15 Coherence Score 0.7021914657763223 Perplexity: -7.812426540058407\n",
      "=======================================================\n",
      "cluster number: 16 Coherence Score 0.6449999280944181 Perplexity: -7.828679543368353\n",
      "=======================================================\n",
      "cluster number: 17 Coherence Score 0.6822947814209058 Perplexity: -7.871092495585947\n",
      "=======================================================\n",
      "cluster number: 18 Coherence Score 0.62381430976621 Perplexity: -7.897046388077275\n",
      "=======================================================\n",
      "cluster number: 19 Coherence Score 0.7077801026517431 Perplexity: -7.94093187935804\n",
      "=======================================================\n",
      "cluster number: 20 Coherence Score 0.697660031716784 Perplexity: -7.976058623907613\n",
      "=======================================================\n",
      "cluster number: 21 Coherence Score 0.657519290423886 Perplexity: -8.021619340323351\n",
      "=======================================================\n",
      "cluster number: 22 Coherence Score 0.6997213463589468 Perplexity: -8.05329210975762\n",
      "=======================================================\n",
      "cluster number: 23 Coherence Score 0.6978865915031044 Perplexity: -8.099267789663477\n",
      "=======================================================\n",
      "cluster number: 24 Coherence Score 0.6583931347006052 Perplexity: -8.15857671682102\n",
      "=======================================================\n",
      "cluster number: 25 Coherence Score 0.6844151027087142 Perplexity: -8.198338571860587\n",
      "=======================================================\n",
      "cluster number: 26 Coherence Score 0.6575868452098069 Perplexity: -8.230975539498708\n",
      "=======================================================\n",
      "cluster number: 27 Coherence Score 0.6648754929898648 Perplexity: -8.278081595416552\n",
      "=======================================================\n",
      "cluster number: 28 Coherence Score 0.6833834133595598 Perplexity: -8.316987689781639\n",
      "=======================================================\n",
      "cluster number: 29 Coherence Score 0.629139645817252 Perplexity: -8.382819644782586\n",
      "=======================================================\n",
      "Wall time: 1h 16min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clusters = list(range(2,30))\n",
    "for k in clusters:   \n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "    # pprint(lda_model.print_topics())\n",
    "    # Compute Perplexity and Coherence Score\n",
    "    Perplexity = lda_model.log_perplexity(corpus)\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=list(repo_data.values()), dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('cluster number:',k, 'Coherence Score',coherence_lda,'Perplexity:',Perplexity)\n",
    "    print('='*55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "=> result: \n",
    "cluster number: 13 Coherence Score 0.7742587187133879 Perplexity: -7.707467603550034\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=13, \n",
    "                                       random_state=100,\n",
    "                                       update_every=1,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       alpha='auto',\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.006*\"ts-jest\" + 0.005*\"graphql\" + 0.005*\"@types/jest\" + 0.005*\"codecov\" + 0.005*\"babel-preset-react\"')\n",
      "(1, '0.007*\"webpack-cli\" + 0.006*\"ajv-errors\" + 0.006*\"webpack\" + 0.006*\"@webassemblyjs/wasm-opt\" + 0.006*\"@webassemblyjs/wasm-edit\"')\n",
      "(2, '0.005*\"@babel/core\" + 0.004*\"eslint\" + 0.004*\"@types/node\" + 0.004*\"@babel/helper-plugin-utils\" + 0.004*\"@babel/helper-module-imports\"')\n",
      "(3, '0.003*\"ansi-escapes\" + 0.003*\"acorn\" + 0.003*\"@babel/core\" + 0.003*\"chalk\" + 0.003*\"@babel/helpers\"')\n",
      "(4, '0.007*\"mocha\" + 0.005*\"eslint\" + 0.005*\"chalk\" + 0.005*\"glob\" + 0.004*\"concat-map\"')\n",
      "(5, '0.003*\"eslint\" + 0.003*\"@babel/core\" + 0.003*\"@babel/preset-env\" + 0.003*\"ansi-styles\" + 0.003*\"@babel/template\"')\n",
      "(6, '0.022*\"pytest\" + 0.021*\"numpy\" + 0.020*\"sphinx\" + 0.014*\"matplotlib\" + 0.014*\"pytest-cov\"')\n",
      "(7, '0.004*\"karma\" + 0.003*\"@types/color-name\" + 0.003*\"ansi-colors\" + 0.003*\"body-parser\" + 0.003*\"accepts\"')\n",
      "(8, '0.007*\"babel-plugin-transform-es2015-modules-umd\" + 0.007*\"babel-helper-call-delegate\" + 0.007*\"babel-plugin-transform-es2015-modules-amd\" + 0.007*\"babel-helper-define-map\" + 0.007*\"babel-helper-replace-supers\"')\n",
      "(9, '0.009*\"sphinx\" + 0.006*\"pytest\" + 0.005*\"escape-html\" + 0.005*\"cookie\" + 0.005*\"finalhandler\"')\n",
      "(10, '0.004*\"array-ify\" + 0.004*\"columnify\" + 0.004*\"conventional-changelog-angular\" + 0.004*\"conventional-commits-parser\" + 0.004*\"compare-func\"')\n",
      "(11, '0.038*\"junit:junit\" + 0.036*\"org.apache.maven.plugins:maven-compiler-plugin\" + 0.028*\"org.apache.maven.plugins:maven-javadoc-plugin\" + 0.026*\"org.apache.maven.plugins:maven-jar-plugin\" + 0.025*\"org.apache.maven.plugins:maven-source-plugin\"')\n",
      "(12, '0.019*\"rake\" + 0.012*\"rspec\" + 0.008*\"minitest\" + 0.008*\"bundler\" + 0.008*\"rubocop\"')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bin\\Anaconda3\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "# Show the top 5 words of each topic\n",
    "for topic in lda_model.print_topics(num_words=5):\n",
    "    print(topic)\n",
    "    \n",
    "# get the possible of each topic\n",
    "lda_model.inference(corpus)[0].shape,lda_model.inference(corpus)[0]\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "pyLDAvis.save_html(vis, 'lda_clus=13.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

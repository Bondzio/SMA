{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data looking:\n",
      "repos nums: 1869\n",
      "repos which have no dependency files: 0\n",
      "repos with dependency files: 1869\n",
      "distinct dependency file: 12947\n",
      "========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\gensim\\models\\doc2vec.py:319: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMEANS:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-8caa7867c192>:79: DeprecationWarning: Call to deprecated `doctag_syn0` (Attribute will be removed in 4.0.0, use docvecs.vectors_docs instead).\n",
      "  X = kmeans_model.fit(d2v_model.docvecs.doctag_syn0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0 : repos num: 1405\n",
      "topic 1 : repos num: 46\n",
      "topic 2 : repos num: 76\n",
      "topic 3 : repos num: 27\n",
      "topic 4 : repos num: 86\n",
      "topic 5 : repos num: 2\n",
      "topic 6 : repos num: 165\n",
      "topic 7 : repos num: 44\n",
      "topic 8 : repos num: 10\n",
      "topic 9 : repos num: 8\n",
      "========================================\n",
      "GMM:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-8caa7867c192>:97: DeprecationWarning: Call to deprecated `doctag_syn0` (Attribute will be removed in 4.0.0, use docvecs.vectors_docs instead).\n",
      "  GMM = GaussianMixture(n_components=k).fit(d2v_model.docvecs.doctag_syn0)\n",
      "<ipython-input-1-8caa7867c192>:98: DeprecationWarning: Call to deprecated `doctag_syn0` (Attribute will be removed in 4.0.0, use docvecs.vectors_docs instead).\n",
      "  probs = GMM.predict_proba(d2v_model.docvecs.doctag_syn0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 1.99674674e-012]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000 0.00000000e+000 ... 2.58109775e-319\n",
      "  0.00000000e+000 3.37617168e-014]\n",
      " ...\n",
      " [1.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 2.58154894e-014]\n",
      " [1.00000000e+000 0.00000000e+000 0.00000000e+000 ... 1.79793673e-303\n",
      "  0.00000000e+000 6.87015377e-022]\n",
      " [1.00000000e+000 0.00000000e+000 0.00000000e+000 ... 3.63613442e-317\n",
      "  0.00000000e+000 4.09114112e-020]]\n",
      "========================================\n",
      "LDA:\n",
      "Perplexity:  -8.75247979015459\n",
      "Coherence Score:  0.6670300120458954\n",
      "(0, '0.029*\"pylint\" + 0.023*\"xarray\" + 0.012*\"protobuf\" + 0.010*\"sphinx-autodoc-typehints\" + 0.009*\"mypy\"')\n",
      "(1, '0.006*\"@babel/parser\" + 0.006*\"@babel/core\" + 0.005*\"@babel/helper-module-imports\" + 0.005*\"@babel/helpers\" + 0.005*\"@babel/helper-optimise-call-expression\"')\n",
      "(2, '0.026*\"junit:junit\" + 0.023*\"org.apache.maven.plugins:maven-compiler-plugin\" + 0.017*\"org.apache.maven.plugins:maven-surefire-plugin\" + 0.013*\"org.apache.maven.plugins:maven-source-plugin\" + 0.011*\"org.apache.maven.plugins:maven-jar-plugin\"')\n",
      "(3, '0.024*\"org.apache.maven.plugins:maven-javadoc-plugin\" + 0.012*\"org.apache.maven.plugins:maven-gpg-plugin\" + 0.008*\"org.sonatype.plugins:nexus-staging-maven-plugin\" + 0.008*\"kramdown\" + 0.008*\"sass\"')\n",
      "(4, '0.017*\"python-dateutil\" + 0.015*\"six\" + 0.015*\"pytz\" + 0.014*\"requests\" + 0.013*\"pyparsing\"')\n",
      "(5, '0.004*\"debug\" + 0.004*\"core-util-is\" + 0.004*\"concat-map\" + 0.004*\"commander\" + 0.004*\"chalk\"')\n",
      "(6, '0.093*\"numpy\" + 0.059*\"scipy\" + 0.053*\"matplotlib\" + 0.051*\"pandas\" + 0.038*\"pytest\"')\n",
      "(7, '0.021*\"nbsphinx\" + 0.015*\"coveralls\" + 0.014*\"twine\" + 0.011*\"mpi4py\" + 0.010*\"tox\"')\n",
      "(8, '0.025*\"tensorflow\" + 0.011*\"load-grunt-tasks\" + 0.009*\"pyserial\" + 0.006*\"gevent\" + 0.005*\"flask-cors\"')\n",
      "(9, '0.008*\"semver\" + 0.007*\"isort\" + 0.006*\"minimatch\" + 0.005*\"wrapt\" + 0.005*\"js-tokens\"')\n",
      "[[0.05810447 0.02687364 0.03236715 ... 0.10543193 0.01991389 0.05671248]\n",
      " [1.0603286  0.02687364 0.03236715 ... 6.201501   0.01991389 1.074665  ]\n",
      " [3.0952764  0.02687364 0.03236715 ... 5.1444044  0.01991389 0.05671248]\n",
      " ...\n",
      " [0.05810447 0.02687364 0.03236715 ... 1.0997568  0.01991389 0.05671248]\n",
      " [0.05810447 0.02687364 0.03236715 ... 0.10542996 0.01991389 0.05671248]\n",
      " [0.05810447 0.02687364 0.03236715 ... 0.10542996 0.01991389 0.05671248]]\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "\n",
    "\n",
    "def load_data(input_file):\n",
    "    '''\n",
    "    input: result_13k.json\n",
    "    output: rep_list,dep_list\n",
    "    '''\n",
    "    with open(input_file) as f:\n",
    "        data = json.load(f)\n",
    "    print(f'repos nums: {len(data)}')\n",
    "\n",
    "    need_to_remove = []\n",
    "    for k,v in data.items():\n",
    "        if 'No dependency' in v:\n",
    "            need_to_remove.append(k)\n",
    "    print(f'repos which have no dependency files: {len(need_to_remove)}')\n",
    "\n",
    "    for k in need_to_remove:\n",
    "        del data[k]\n",
    "    print(f'repos with dependency files: {len(data)}')\n",
    "\n",
    "    rep_list,dep_list = [],[]\n",
    "    for k,v in data.items():\n",
    "        rep_list.append(k)\n",
    "        dep_list.append(v)\n",
    "        \n",
    "    dep_dict = {}\n",
    "    for deps in data.values():\n",
    "        for i in deps:\n",
    "            dep_dict[i] = dep_dict.get(i,0)+1\n",
    "\n",
    "    print(f'distinct dependency file: {len(dep_dict)}')\n",
    "\n",
    "    return rep_list,dep_list,data\n",
    "    ### rep_list format :  ['https://github.com/AgriculturalModelExchangeInitiative/Crop2ML'  ... ]\n",
    "    ### dep_list format: [['ipython', 'jupyter-sphinx', 'nbformat', 'nbsphinx', 'path-py', 'six', 'sphinx', \n",
    "    #                      'sphinx-hoverxref', 'sphinx-rtd-theme'], ['pypng', 'requests'],  ....] \n",
    "    ### data format: {repo1: [dep1,dep2], ...}\n",
    "\n",
    "def d2v(dep_list):\n",
    "    LabeledSentence1 = gensim.models.doc2vec.TaggedDocument\n",
    "    all_content_train = []\n",
    "    j=0\n",
    "    for em in dep_list:\n",
    "        all_content_train.append(LabeledSentence1(em,[j]))\n",
    "        j+=1\n",
    "    d2v_model = Doc2Vec(all_content_train, \n",
    "                    size = 100, \n",
    "                    window = 10, \n",
    "                    min_count = 1, \n",
    "                    workers=7, \n",
    "                    dm = 1,\n",
    "                    alpha=0.025, \n",
    "                    min_alpha=0.001)\n",
    "    d2v_model.train(all_content_train, \n",
    "                    total_examples=d2v_model.corpus_count, \n",
    "                    epochs=10, \n",
    "                    start_alpha=0.002, \n",
    "                    end_alpha=-0.016)\n",
    "\n",
    "    return d2v_model\n",
    "    ### d2v_model can be seen as a list, each item represents a doc vector \n",
    "\n",
    "def kmeans(k,d2v_model,rep_list):\n",
    "    kmeans_model = KMeans(n_clusters=k, init='k-means++', max_iter=500) \n",
    "    X = kmeans_model.fit(d2v_model.docvecs.doctag_syn0)\n",
    "    labels=kmeans_model.labels_\n",
    "\n",
    "    topic_dict = {}\n",
    "    for index,label in enumerate(labels):\n",
    "        topic_id = label\n",
    "        # print(topic_id, '--->', rep_list[index])\n",
    "        topic_dict[label] = topic_dict.get(label,[])\n",
    "        topic_dict[label].append(rep_list[index])\n",
    "\n",
    "    for k in sorted(topic_dict.keys()):\n",
    "        print(f'topic {k} : repos num: {len(topic_dict[k])}')\n",
    "\n",
    "    return topic_dict\n",
    "    ## topic_dict is a dictionary whose key is the topic and value is a list of repos\n",
    "    ## format {top1:  [repo1,repo2] ....}\n",
    "\n",
    "def gmm(k,d2v_model):\n",
    "    GMM = GaussianMixture(n_components=k).fit(d2v_model.docvecs.doctag_syn0)\n",
    "    probs = GMM.predict_proba(d2v_model.docvecs.doctag_syn0)\n",
    "    #probs.shape,probs\n",
    "    return probs\n",
    "\n",
    "### LDA ### \n",
    "def LDA(data,rep_list):\n",
    "    # based on dep file names , build dep name dictionary\n",
    "    id2word  = corpora.Dictionary(list(data.values()))   # {0: 'emd-signal',1: 'numpy', 2: 'SQLAlchemy' ...}\n",
    "    # based on dep name dict and dep names, build corpus\n",
    "    corpus = [id2word.doc2bow(text) for text in list(data.values())] # [[(0, 1), (1, 1)],.....]\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "    # pprint(lda_model.print_topics())\n",
    "\n",
    "    print('Perplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=list(data.values()), dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('Coherence Score: ', coherence_lda)\n",
    "\n",
    "    # Show the top 5 words of each topic\n",
    "    for topic in lda_model.print_topics(num_words=5):\n",
    "        print(topic)\n",
    "\n",
    "    # get the possible of each topic\n",
    "    probs = lda_model.inference(corpus)[0]\n",
    "\n",
    "    # inference\n",
    "    topic_dict = {}\n",
    "    for e, values in enumerate(lda_model.inference(corpus)[0]):\n",
    "        topic_val = 0\n",
    "        topic_id = 0\n",
    "        for tid, val in enumerate(values):\n",
    "            if val > topic_val:\n",
    "                topic_val = val\n",
    "                topic_id = tid        \n",
    "        topic_dict[topic_id] = topic_dict.get(topic_id,[])\n",
    "        topic_dict[topic_id].append(rep_list[e])\n",
    "\n",
    "    return probs,topic_dict\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = '../data/dependency_data_8k.json'\n",
    "    # load data\n",
    "    print('Data looking:')\n",
    "    rep_list,dep_list,data = load_data(input_file)\n",
    "    print('='*40)\n",
    "    #doc2vector\n",
    "    d2v_model = d2v(dep_list)\n",
    "    # kmeans\n",
    "    print('KMEANS:')\n",
    "    topic_dict = kmeans(10,d2v_model,rep_list)\n",
    "    print('='*40)\n",
    "    # gmm\n",
    "    print('GMM:')\n",
    "    probs = gmm(10,d2v_model)\n",
    "    print(probs)\n",
    "    print('='*40)\n",
    "    \n",
    "    # LDA\n",
    "    print('LDA:')\n",
    "    probs_lds, topic_dict_lda = LDA(data,rep_list)\n",
    "    print(probs_lds)\n",
    "    print('='*40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
